{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Journalism: Recap Data wrangling\n",
    "\n",
    "Penny Sheets and Damian Trilling\n",
    "\n",
    "In this recap notebook, we exercise with data wrangling techniques.\n",
    "\n",
    "Also have a look at this Cheat Sheet:\n",
    "https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\n",
    "\n",
    "**To follow this example, you need to `pip install tabula-py` first!**\n",
    "\n",
    "\n",
    "Also, have a look at this PDF: http://www.ametsoc.net/sotc2017/StateoftheClimate2017_lowres.pdf\n",
    "We will try to get the table from page 113 ( Global tropical cyclone counts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!! This is an example of a table that is *really* messed up, but short, so you might just type it over instead. But that's a great way to demonstrate the techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns out that what is called p. 113 is actually page 163 (b/c of front matter of the book in different numbering)\n",
    "df = tabula.read_pdf('http://www.ametsoc.net/sotc2017/StateoftheClimate2017_lowres.pdf',  \n",
    "                     multiple_tables=False, pages=133)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first get only the rows that really contain data\n",
    "datarows = df.iloc[1:8]\n",
    "datarows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUT, let's fix the index so that it starts with 0 (important for some stuff later ('concatenating'))\n",
    "datarows.index=range(7)\n",
    "datarows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**?What is right already, and what needs to be fixed?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datarows.iloc[:,0]   # all rows, column 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the cells on their spaces and retain only the last four values\n",
    "datarows.iloc[:,0].map(lambda x: x.split()[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... let's turn this into an own dataframe (instead of just showing it) [for this, we first make it a list of lists]\n",
    "tmpdf1 = pd.DataFrame(datarows.iloc[:,0].map(lambda x: x.split()[-4:]).to_list())\n",
    "tmpdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's give it better columnnames:\n",
    "tmpdf1.columns = ['Tropical Depressions', 'Tropical Storms', 'HurricanTropicalCyclon', 'Major HurricanTropicalCyclon']\n",
    "tmpdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's concatenate (=glue together) with our data frame from above\n",
    "newdf = pd.concat([datarows,tmpdf1], axis=1)\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fix the first names\n",
    "oldcolumnnames = newdf.columns.to_list()\n",
    "oldcolumnnames[0] = 'Basin'\n",
    "oldcolumnnames[1] = 'SS Cat5'\n",
    "oldcolumnnames[2] = 'ACE'\n",
    "newdf.columns = oldcolumnnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix Basin name - same as above, but we now retain everything UNTIl the last 4 elements, \n",
    "# and then join the first elements with a space again\n",
    "newdf['Basin'] = newdf['Basin'].map(lambda x: \" \".join(x.split()[:-4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wanna reorder?\n",
    "cols = newdf.columns.to_list()\n",
    "neworder = [cols[0], cols[3], cols[4], cols[5], cols[6], cols[1], cols[2]]\n",
    "reconstructed_table = newdf[neworder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
