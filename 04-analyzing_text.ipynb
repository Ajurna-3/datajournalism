{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Journalism\n",
    "## Practical Python exercise: Analyzing text\n",
    "\n",
    "*Damian Trilling and Penny Sheets*\n",
    "\n",
    "This notebook is meant to show you some more ways of analyzing data that go beyond methods like `df.describe()` or `Counter()` etc., which we used last week already. In particular, we are going to look into analyzing textual data.\n",
    "\n",
    "We will both look at *bottom up* and *top down* approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "We will use a dataset by Schumacher et al. (2016). From the abstract:\n",
    "> This paper presents EUSpeech, a new dataset of 18,403 speeches from EU leaders (i.e., heads of government in 10 member states, EU commissioners, party leaders in the European Parliament, and ECB and IMF leaders) from 2007 to 2015. These speeches vary in sentiment, topics and ideology, allowing for fine-grained, over-time comparison of representation in the EU. The member states we included are Czech Republic, France, Germany, Greece, Netherlands, Italy, Spain, United Kingdom, Poland and Portugal.\n",
    "\n",
    "Schumacher, G, Schoonvelde, M., Dahiya, T., Traber, D, & de Vries, E. (2016): *EUSpeech: a New Dataset of EU Elite Speeches*. [doi:10.7910/DVN/XPCVEI](http://dx.doi.org/10.7910/DVN/XPCVEI)\n",
    "\n",
    "Download and unpack the following file:\n",
    "```\n",
    "speeches_csv.tar.gz\n",
    "```\n",
    "\n",
    "In the .tar.gz file, you find a .zip file.\n",
    "See below a screenshot of how this looks like in Lubuntu (double-click on \"speeches_csv.zip\" in the left window, then the right window will open. Click on \"Extract\"). On some systems, you need to actually to three steps of uncompressing: double-click on the tar.gz file to make it a .gz file, and double-click on that one to get the zip file, and then the same thing again for the zip file.\n",
    "\n",
    "\n",
    "**Within that archive, you find a file `Speeches_UK_Cleaned.csv`. That's the one we need -- save it inthe directory in which you save your Jupyter Notebooks!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"https://github.com/damian0604/bdaca/raw/master/ipynb/euspeech_download.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "It is a good custom to import all modules that you need at the beginning of your notebook. I'll explain in the leson what these models do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "# from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "First of all, we will read the dataset in a Pandas Dataframe. In this case, it seems that there are no column headers (try to run it without the header-argument to see what happens!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Speeches_UK_Cleaned.csv', header=None)   # the first line contains already data and not column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[33:37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now probably got some sense what the columns mean, so let's give them headers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns = ['what','when','country','who','number', 'text', 'text_clean','language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>what</th>\n",
       "      <th>when</th>\n",
       "      <th>country</th>\n",
       "      <th>who</th>\n",
       "      <th>number</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EU Council: PM press conference</td>\n",
       "      <td>18-12-2015</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>D. Cameron</td>\n",
       "      <td>2877</td>\n",
       "      <td>&lt;p&gt;This European Council has focused on 3 issu...</td>\n",
       "      <td>european council focus issu uk renegoti migrat...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PM statement in Poland: 10 December 2015</td>\n",
       "      <td>10-12-2015</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>D. Cameron</td>\n",
       "      <td>866</td>\n",
       "      <td>&lt;p&gt;Thank you Prime Minister for welcoming me h...</td>\n",
       "      <td>thank prime minist welcom warsaw honour first ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PM statement on talks in Romania, 9 December 2015</td>\n",
       "      <td>09-12-2015</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>D. Cameron</td>\n",
       "      <td>726</td>\n",
       "      <td>&lt;p&gt;Thank you President Iohannis for welcoming ...</td>\n",
       "      <td>thank presid iohanni welcom bucharest today pl...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PM Speech: This is a government that delivers</td>\n",
       "      <td>07-12-2015</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>D. Cameron</td>\n",
       "      <td>6211</td>\n",
       "      <td>&lt;p&gt;This is a government that delivers&lt;/p&gt;&lt;p&gt;Th...</td>\n",
       "      <td>govern deliversthank much brief introduct grea...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PM Bulgaria visit 3 December 2015: press confe...</td>\n",
       "      <td>07-12-2015</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>D. Cameron</td>\n",
       "      <td>773</td>\n",
       "      <td>&lt;p&gt;Well thank you very much Prime Minister, th...</td>\n",
       "      <td>well thank much prime minist thank boyko good ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                what        when  \\\n",
       "0                    EU Council: PM press conference  18-12-2015   \n",
       "1           PM statement in Poland: 10 December 2015  10-12-2015   \n",
       "2  PM statement on talks in Romania, 9 December 2015  09-12-2015   \n",
       "3      PM Speech: This is a government that delivers  07-12-2015   \n",
       "4  PM Bulgaria visit 3 December 2015: press confe...  07-12-2015   \n",
       "\n",
       "         country         who  number  \\\n",
       "0  Great Britain  D. Cameron    2877   \n",
       "1  Great Britain  D. Cameron     866   \n",
       "2  Great Britain  D. Cameron     726   \n",
       "3  Great Britain  D. Cameron    6211   \n",
       "4  Great Britain  D. Cameron     773   \n",
       "\n",
       "                                                text  \\\n",
       "0  <p>This European Council has focused on 3 issu...   \n",
       "1  <p>Thank you Prime Minister for welcoming me h...   \n",
       "2  <p>Thank you President Iohannis for welcoming ...   \n",
       "3  <p>This is a government that delivers</p><p>Th...   \n",
       "4  <p>Well thank you very much Prime Minister, th...   \n",
       "\n",
       "                                          text_clean language  \n",
       "0  european council focus issu uk renegoti migrat...       en  \n",
       "1  thank prime minist welcom warsaw honour first ...       en  \n",
       "2  thank presid iohanni welcom bucharest today pl...       en  \n",
       "3  govern deliversthank much brief introduct grea...       en  \n",
       "4  well thank much prime minist thank boyko good ...       en  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottom-up analysis\n",
    "\n",
    "As the texts by Boumans and Trilling and by Kitchin outlined, there are several approaches to data analysis: bottom up and top down. With the former, you try to recognize patterns and describe the data; with the latter, you aim at identifying concepts you have defined in advance. Let's start bottom-up.t\n",
    "\n",
    "\n",
    "I give some examples in the following lines, *but try out your own stuff!!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['who'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that in Python, everything is an object. Therefore, we can *chain* methods and apply the `.plot()` method to the output object of `.value_counts()` if we want to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['who'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple bottom-up approaches to text analysis\n",
    "\n",
    "Let's get most common words. The command below basically takes all cleaned texts, joins them together with a space between them, and then splits this long string into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = Counter(\" \".join(df.text_clean).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a word cloud instead!\n",
    "\n",
    "More  examples at https://github.com/amueller/word_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mywordcloud = WordCloud(width=800, height=400).generate(\" \".join(df.text_clean))\n",
    "plt.imshow(mywordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mywordcloud.to_file('mywordcloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mywordcloud?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see what happens if we only take some of the speeches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allspeechesbycameron = \" \".join(df[df['who']=='D. Cameron']['text_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allspeechesbycameron[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(allspeechesbycameron.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=800, height=400).generate(allspeechesbycameron)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's turn it around and look for specific things (top-down)\n",
    "\n",
    "Imagine we are interested in references to `terror`. Feel free to choose any other term!\n",
    "\n",
    "We can actually use regular expressions (google for it!), so we can use `[tT]error` to allow for both upper and lower case. Or we can say `[tT]erroris[mt]`.\n",
    "\n",
    "Let's first look at it and then make a new column with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       7\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       2\n",
       "5       0\n",
       "6       2\n",
       "7       9\n",
       "8       4\n",
       "9      20\n",
       "10      0\n",
       "11      1\n",
       "12     22\n",
       "13      0\n",
       "14      9\n",
       "15      0\n",
       "16      0\n",
       "17      1\n",
       "18      2\n",
       "19      0\n",
       "20      0\n",
       "21      2\n",
       "22      1\n",
       "23      0\n",
       "24      0\n",
       "25      0\n",
       "26      1\n",
       "27     11\n",
       "28     17\n",
       "29      0\n",
       "       ..\n",
       "757     1\n",
       "758     1\n",
       "759     0\n",
       "760     3\n",
       "761     0\n",
       "762     0\n",
       "763     0\n",
       "764     0\n",
       "765     0\n",
       "766     0\n",
       "767     0\n",
       "768     0\n",
       "769     0\n",
       "770     0\n",
       "771     0\n",
       "772     0\n",
       "773     0\n",
       "774     0\n",
       "775     1\n",
       "776     1\n",
       "777    11\n",
       "778     0\n",
       "779     0\n",
       "780     1\n",
       "781     8\n",
       "782     0\n",
       "783     0\n",
       "784     0\n",
       "785     0\n",
       "786     0\n",
       "Name: text, Length: 787, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.count('[tT]error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['terrorrefs'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "687"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['terrorrefs'].idxmax() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "what            Permanent Link to Press conference in Islamabad\n",
       "when                                                 14-12-2008\n",
       "country                                           Great Britain\n",
       "who                                                    G. Brown\n",
       "number                                                     2954\n",
       "text          <p>Transcript of a press conference given by t...\n",
       "text_clean    transcript press confer given prime minist mr ...\n",
       "language                                                     en\n",
       "terrorrefs                                                   44\n",
       "Name: 687, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[687]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making comparisons\n",
    "\n",
    "Of course, it would be cool to get some idea whether this differs between some groups of speeches. For this, we can use subsetting (see last week) and repeat the analysis three times, or we can use `.groupby`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('who')['terrorrefs'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('who')['terrorrefs'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of counting the number of all references to terror, let's count the number of speeches that have at leas tone reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['terrorrefsdummy'] = df['terrorrefs']>0\n",
    "df['terrorrefsdummy'] = df['terrorrefsdummy'].map(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('who')['terrorrefsdummy'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following lines, you find a quick preview of what we will do a bit more next week: joining tables. Remember that the output generated above can be seen as just another object, which we can turn into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terrorspeeches = df.groupby('who')['terrorrefsdummy'].sum()\n",
    "totalspeeches = df['who'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(terrorspeeches)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= pd.DataFrame(totalspeeches)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.join(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = df1.join(df2)\n",
    "df3.columns = ['speeches about terror','total speeches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3['ratio'] = df3['speeches about terror']/df3['total speeches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[['speeches about terror', 'total speeches']].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['ratio'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going in-depth\n",
    "We created new columns above to indicate whether a speech was about terrorism or not. We can now reuse this to actually read such a speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['terrorrefsdummy'] == True]['what'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['what'] == \"PM's speech to the Jamaican Parliament\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['what'] == \"PM's speech to the Jamaican Parliament\"]['text'].str.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['words'] = df['text'].map(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='words', y='number', style='x')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
